{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data File**"
      ],
      "metadata": {
        "id": "OzWgZj-xtKAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads the file's contents and saves it to the notebook's files."
      ],
      "metadata": {
        "id": "kN_5bb4f1NYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ziab3ELCOt-v"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "data_file = \"reddit_comments.csv\"\n",
        "\n",
        "request = requests.get(\"https://drive.google.com/uc?export=download&id=1grbBKQ8SEcujIYSTiKaDbOXbFpuhTijv\")\n",
        "with open(data_file, \"wb\") as file:\n",
        "    file.write(request.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Dataset and General Setup**"
      ],
      "metadata": {
        "id": "LP-RHOgEumpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You only need to run the `!pip3 install` code blocks once per session."
      ],
      "metadata": {
        "id": "olD0J6oPuXu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers==4.28.0"
      ],
      "metadata": {
        "id": "-cm28qcZBBuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Seed\n",
        "\n",
        "You need to run this before the Load and Partition Dataset section to ensure the train, valid and test partitions are the same."
      ],
      "metadata": {
        "id": "FwOG_Gt113fJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "NZAnAM5317Zw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Partition Dataset"
      ],
      "metadata": {
        "id": "ILpw3Ixu1_47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict, Features, ClassLabel, Value\n",
        "\n",
        "dataset = load_dataset('csv', data_files=data_file, split=\"train\", download_mode=\"reuse_cache_if_exists\")\n",
        "\n",
        "train_testvalid = dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
        "\n",
        "final_dataset = DatasetDict({\n",
        "    'train': train_testvalid['train'],\n",
        "    'test': test_valid['test'],\n",
        "    'valid': test_valid['train']})\n",
        "\n",
        "print(final_dataset)"
      ],
      "metadata": {
        "id": "aPAk6yu81-bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_dataset_divide(dataset_partition, partition_name):\n",
        "  count_pos = 0\n",
        "  count_neg = 0\n",
        "  for entry in dataset_partition:\n",
        "    if entry[\"label\"] == 0:\n",
        "      count_neg += 1\n",
        "    else: #entry[\"label\"] == 1:\n",
        "      count_pos += 1\n",
        "  print(\"partition_name:\", partition_name)\n",
        "  print(\"positive_count: \", count_pos)\n",
        "  print(\"negative_count: \", count_neg)"
      ],
      "metadata": {
        "id": "dVtiP2u72Mys"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine Final Dataset"
      ],
      "metadata": {
        "id": "erIWiMVU2TIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_dataset_divide(final_dataset[\"train\"], \"Train\")\n",
        "print(final_dataset[\"train\"][0], \"\\n\")\n",
        "count_dataset_divide(final_dataset[\"test\"], \"Test\")\n",
        "print(final_dataset[\"test\"][0], \"\\n\")\n",
        "count_dataset_divide(final_dataset[\"valid\"], \"Valid\")\n",
        "print(final_dataset[\"valid\"][0], \"\\n\")"
      ],
      "metadata": {
        "id": "ROiFwyBw2SWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test**"
      ],
      "metadata": {
        "id": "faGsXYLT2aEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU/CPU"
      ],
      "metadata": {
        "id": "r8I8e0xx2Zyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "KzHmPOaJ2ZUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"distilbert-base-uncased\""
      ],
      "metadata": {
        "id": "tiBVuVqd30XN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer"
      ],
      "metadata": {
        "id": "_YyMq39V2lK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "    \n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
      ],
      "metadata": {
        "id": "dZInoY492mr_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode Dataset"
      ],
      "metadata": {
        "id": "AwHSk5-z21ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(entries):\n",
        "    return tokenizer(entries[\"comment\"], padding=True, truncation=True)\n",
        "\n",
        "encoded_test_dataset = final_dataset[\"test\"].map(preprocess_function, batched=True, load_from_cache_file=False)"
      ],
      "metadata": {
        "id": "_Ww5Hy3p2qek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test**"
      ],
      "metadata": {
        "id": "gPZHfZCx1lgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, Trainer\n",
        "\n",
        "model_name = \"AG6019/reddit-comment-sentiment-final\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "test_trainer = Trainer(model)"
      ],
      "metadata": {
        "id": "2dzv6Es7xX9T"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "def compute_metrics(y_pred, labels):\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=y_pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=y_pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=y_pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=y_pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "metadata": {
        "id": "p0phR3DnznNp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions on test set"
      ],
      "metadata": {
        "id": "u7h74LP_kSIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pred , _, _ = test_trainer.predict(encoded_test_dataset)"
      ],
      "metadata": {
        "id": "TFKvCG9j4d23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate test set"
      ],
      "metadata": {
        "id": "OULhQ_oVkXrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "y_pred = np.argmax(raw_pred, axis=1)\n",
        "\n",
        "labels = np.array(final_dataset[\"test\"][\"label\"])\n",
        "\n",
        "metrics = compute_metrics(y_pred, labels)\n",
        "print(\"Evaluation Metrics\")\n",
        "print(metrics, \"\\n\")\n",
        "\n",
        "conf_matrix = tf.math.confusion_matrix(labels, y_pred, num_classes=2)\n",
        "print(\"Confusion Matrix\")\n",
        "print(conf_matrix, \"\\n\")"
      ],
      "metadata": {
        "id": "cwQuJkqMzxw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examples from testing set"
      ],
      "metadata": {
        "id": "-YBlPkhLkZ6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ex_indices = [1, 2, 9, 10, 11, 58]\n",
        "\n",
        "print(\"Test Examples\")\n",
        "for i in test_ex_indices:\n",
        "  print(final_dataset[\"test\"][\"comment\"][i])\n",
        "  print(\"raw prediction:\", raw_pred[i])\n",
        "  print(\"actual:\", labels[i])\n",
        "  print(\"predicted:\", y_pred[i])\n",
        "  print()"
      ],
      "metadata": {
        "id": "AoAItdkdljZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}